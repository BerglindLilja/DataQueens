{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f675caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "70e20697",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = 'https://lotr.fandom.com/api.php?'\n",
    "action = \"action=query\"\n",
    "listt = \"list=categorymembers\"\n",
    "cmtitleMajor = \"cmtitle=Category:Major_characters_(The_Lord_of_the_Rings)\"\n",
    "cmtitleMinor = \"cmtitle=Category:Minor_characters_(The_Lord_of_the_Rings)\"\n",
    "cmtitleVilla = \"cmtitle=Category:Villains\"\n",
    "\n",
    "cmtitle1 = \"cmtitle=Category:The_Lord_of_the_Rings:_The_Fellowship_of_the_Ring_(film)_Characters\"\n",
    "cmtitle2 = \"cmtitle=Category:The_Lord_of_the_Rings:_The_Two_Towers_(film)_Characters\"\n",
    "cmtitle3 = \"cmtitle=Category:The_Lord_of_the_Rings:_The_Return_of_the_King_(film)_Characters\"\n",
    "\n",
    "cmlimit = \"cmlimit=max\"\n",
    "content = \"prop=revisions&rvprop=content&rvslots=*\"\n",
    "dataformat =\"format=json\"\n",
    "\n",
    "query1 = \"{}{}&{}&{}&{}&{}&{}\".format(baseurl, action, listt, cmtitle1, cmlimit, content, dataformat)\n",
    "query2 = \"{}{}&{}&{}&{}&{}&{}\".format(baseurl, action, listt, cmtitle2, cmlimit, content, dataformat)\n",
    "query3 = \"{}{}&{}&{}&{}&{}&{}\".format(baseurl, action, listt, cmtitle3, cmlimit, content, dataformat)\n",
    "\n",
    "# print(query1)\n",
    "# print(query2)\n",
    "# print(query3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "05572993",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiresponse1 = urllib.request.urlopen(query1)\n",
    "wikiresponse2 = urllib.request.urlopen(query2)\n",
    "wikiresponse3 = urllib.request.urlopen(query3)\n",
    "\n",
    "wikidata1 = wikiresponse1.read()\n",
    "wikidata2 = wikiresponse2.read()\n",
    "wikidata3 = wikiresponse3.read()\n",
    "\n",
    "wikitext1 = wikidata1.decode('utf-8')\n",
    "wikitext2 = wikidata2.decode('utf-8')\n",
    "wikitext3 = wikidata3.decode('utf-8')\n",
    "\n",
    "characters1 = json.loads(wikitext1)\n",
    "characters2 = json.loads(wikitext2)\n",
    "characters3 = json.loads(wikitext3)\n",
    "\n",
    "# charectersContent = charecters['query']['pages']['41']['revisions'][0]['slots']['main']['*']\n",
    "content1 = characters1['query']['categorymembers']\n",
    "content2 = characters2['query']['categorymembers']\n",
    "content3 = characters3['query']['categorymembers']\n",
    "\n",
    "# print(charactersContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "62c0f4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024531\n"
     ]
    }
   ],
   "source": [
    "books = [\"01 - The Fellowship Of The Ring.txt\", \"02 - The Two Towers.txt\", \"03 - The Return Of The King.txt\"]\n",
    "\n",
    "# for book in list_of_books:\n",
    "with open(\"books/\" + list_of_books[0], encoding=\"ISO-8859-1\") as f:\n",
    "    theText = f.read()\n",
    "    \n",
    "print(len(theText))\n",
    "# for book in books:\n",
    "\n",
    "    # generate the text object needed to compute frequencies\n",
    "#     nltk_text = nltk.Text(book)\n",
    "#     print(nltk_text)\n",
    "    \n",
    "#     # Generate the frequency distribution\n",
    "#     fdist = nltk.FreqDist(nltk_text)\n",
    "    \n",
    "#     # Assign them to each book dictionary\n",
    "#     book['fdist'] = fdist\n",
    "    \n",
    "#     # generate the normalized frequencies - here normalized by the length of the clean text\n",
    "#     fdist_norm = copy.deepcopy(fdist)\n",
    "    \n",
    "#     # Extract the length of the clean text\n",
    "#     length = book['all_text_clean_length']\n",
    "    \n",
    "#     # Loop through each word and divide the frequency with the length of the document\n",
    "#     for word in fdist_norm:\n",
    "#         fdist_norm[word] = fdist[word] / length\n",
    "\n",
    "#     # Assign the normalized frequency distribution to the dictionaries of books\n",
    "#     book['fdist_norm'] = fdist_norm\n",
    "\n",
    "# file1 = open(\"books/\" + book)\n",
    "# theText = text.read().decode('utf8')\n",
    "# print(theText)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
